---
title: "iShares"
author: "Harald Puhr"
date: "20 6 2020"
output: html_document
---

```{r setup, include = FALSE}
dir_ishares <- "Z:/portfolio"
dir_overview <- file.path(dir_ishares, "ishares_overview")
dir_price <- file.path(dir_ishares, "ishares_price")
dir_dividends <- file.path(dir_ishares, "ishares_dividends")

lst_urls <- readr::read_tsv(file.path(dir_ishares, "data_ishares_url.tsv"))
```

# Basic idea

The basic idea of this script is download information on ETFs that are part of the iShares family, published by Blackrock. Blackrock provides basic information on for each ETF on the respective fund's website. The aim of this code is to:

- Download and extract data for a number of ETFs
- Convert to Euro returns and save data
- Summarize the data

The code uses the following `R` packages:

```{r, echo = TRUE, results = "hide", warning = FALSE, message = FALSE}
library(progress)
library(tidyverse)
library(xml2)
```


# Download and extract data

Blackrock shows detailed information on its various iShares ETFs on the ETF's website (e.g. [iShares Core â‚¬ Corp Bond UCITS ETF](https://www.ishares.com/de/privatanleger/de/produkte/251726/ishares-euro-corporate-bond-ucits-etf/)). For each ETF, Blackrock provides an Excel file for download covering fundamental information, historic prices, positions, and dividends. I limit the analysis to [iShare's most popular standard and ESG ETFs](https://www.ishares.com/de/privatanleger/de/anlegen/bestseller). A list of ETF names and URLs to the respective Excel file is the basis for the analysis:

```{r, echo = FALSE}
head(lst_urls)
```

## Get XML data

The Excel files provided by iShares are not "real" Excel files but are instead XML files created in Excel. The first step is therefore to download the XML file from iShares, fix some encoding issues in the first line for for the character *&*.

```{r}
get_xml <- function(etf_url) {
  file_raw <- tempfile()
  file_xml <- tempfile()
  download.file(etf_url, file_raw)
  txt <- readLines(file_raw, encoding = "UTF-8-BOM")
  txt[1] <- "<?xml version=\"1.0\"?>"
  txt <- str_replace_all(txt, "S&P", "SP")
  write_lines(txt, file_xml)
  out <- read_xml(file_xml)
  return(out)
}
```

The output from the `get_xml` function is an XML file with 6 nodes:

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data_xml <- get_xml(lst_urls$url[1])
data_xml
```

## Extract sheet "Overview"

The XML node #2 contains the sheet "Overview". The following function loops through all cells of the Excel sheet and extracts the overview information.

```{r}
extract_overview <- function(data_xml) {
  xml_overview <- data_xml %>%
    xml_child(2) %>%
    xml_child(1)
  
  cnt_rows <- xml_length(xml_overview)
  
  out_cols <- vector(mode = "character", length = 2)
  out_rows <- vector(mode = "list", length = cnt_rows - 4)
  
  pb <- progress_bar$new(total = cnt_rows, format = "[:bar] :percent")
  
  for (i in seq(5, cnt_rows)) {
    xml_row <- xml_overview %>%
      xml_child(i)
    
    out_cols[[1]] <- xml_row %>%
      xml_child(1) %>%
      xml_text()
    
    out_cols[[2]] <- xml_row %>%
      xml_child(2) %>%
      xml_text()
    
    out_rows[[i - 4]] <- out_cols
    pb$tick()
  }
  
  out <- map_dfr(out_rows, ~ tibble(parameter = .x[1], value = .x[2]))
  return(out)
}
```


The output from the `extract_overview` function is a tibble with two columns containing the basic ETF information:

```{r, echo = FALSE, warning = FALSE, message = FALSE}
extract_overview(data_xml)
```

## Extract sheet "Historic"

The XML node #4 contains the sheet "Historic". The following function loops through all cells of the Excel sheet and extracts information on historic prices. Since looping through 7 columns * > 1000 rows is time consuming, the function checks whether this information has alredy been extracted previously. It compares the number of rows of the output file `[etf_name]_price.tsv` to the downloaded file and extracts only the rows not contained in the output file.

```{r}
extract_historic <- function(data_xml, file_price){
  xml_price <- data_xml %>%
    xml_child(4) %>%
    xml_child(1)

  if (file.exists(file_price)) {
    old_price <- read_tsv(file_price)
    cnt_rows <- min(xml_length(xml_price), xml_length(xml_price) - nrow(old_price) + 5)
  } else {
    cnt_rows <- xml_length(xml_price)
  }
  
  out_cols <- vector(mode = "character", length = 3)
  out_rows <- vector(mode = "list", length = cnt_rows - 1)
  
  pb <- progress_bar$new(total = cnt_rows - 1, format = "[:bar] :percent")
  
  for (i in seq(2, cnt_rows)) {
    xml_row <- xml_price %>%
      xml_child(i)
    
    out_cols[[1]] <- xml_row %>%
      xml_child(1) %>%
      xml_text()
    
    out_cols[[2]] <- xml_row %>%
      xml_child(2) %>%
      xml_text()
    
    out_cols[[3]] <- xml_row %>%
      xml_child(3) %>%
      xml_text()
    
    out_rows[[i - 1]] <- out_cols
    pb$tick()
  }
  
  out <- map_dfr(out_rows, ~ tibble(date = .x[1], currency = .x[2], price = .x[3]))
  return(out)
}
```

The output from the `extract_price` function is a tibble with three columns containing historic ETF information (date, currency, price ~ NAV):

```{r, echo = FALSE, warning = FALSE, message = FALSE}
extract_historic(data_xml, file.path(dir_price, str_c(lst_urls$name[1], "_price.tsv")))
```

## Extract sheet "Dividends"

The XML node #6 (if included in the XML file) contains the sheet "Dividends". The following function loops through all cells of the Excel sheet and extracts information on dividends. Like for the sheet "Historic", looping through all cells can be time consuming. Again, the function checks whether this information has alredy been extracted previously and compares the number of rows of the output file `[etf_name]_dividends.tsv` to the downloaded file and extracts only the rows not contained in the output file.

```{r}
extract_dividends <- function(data_xml, file_dividends){
  if (xml_length(data_xml) == 6) {
    xml_dividends <- data_xml %>%
      xml_child(6) %>%
      xml_child(1)
    
    if (file.exists(file_dividends)) {
      old_dividends <- read_tsv(file_dividends)
      cnt_rows <- min(xml_length(xml_dividends), xml_length(xml_dividends) - nrow(old_dividends) + 5)
    } else {
      cnt_rows <- xml_length(xml_dividends)
    }
    
    out_cols <- vector(mode = "character", length = 2)
    out_rows <- vector(mode = "list", length = cnt_rows - 1)
    
    pb <- progress_bar$new(total = cnt_rows - 1, format = "[:bar] :percent")
    
    for (i in seq(2, cnt_rows)) {
      xml_row <- xml_dividends %>%
        xml_child(i)
      
      out_cols[[1]] <- xml_row %>%
        xml_child(1) %>%
        xml_text()
      
      out_cols[[2]] <- xml_row %>%
        xml_child(4) %>%
        xml_text()
      
      out_rows[[i - 1]] <- out_cols
      pb$tick()
    }
    
    out <- map_dfr(out_rows, ~ tibble(date = .x[1], dividend = .x[2]))
  } else {
    out <- tibble(date = NA, dividend = NA)
  }
  return(out)
}
```

The output from the `extract_dividends` function is a tibble with two columns containing ETF dividends (date, dividend):

```{r, echo = FALSE, warning = FALSE, message = FALSE}
extract_dividends(data_xml, file.path(dir_dividends, str_c(lst_urls$name[1], "_dividends.tsv")))
```

## Clean download data

The next step after the download is to clean the data. The data cleaning basically consists of changing some special characters and converting character columns to numeric and date. The results are saved as:

- `[etf_name]_overview.tsv`
- `[etf_name]_prices.tsv`
- `[etf_name]_dividends.tsv`

```{r}
clean_overview <- function(data_overview) {
  data_overview <- data_overview %>%
    mutate(parameter = str_replace_all(parameter, "\u00C3\u00a4", "\u00e4"))%>%
    mutate(parameter = str_replace_all(parameter, "\u00C3\u00b6", "\u00f6"))%>%
    mutate(parameter = str_replace_all(parameter, "\u00C3\u00bc", "\u00fc")) %>%
    mutate(parameter = str_remove_all(parameter, "\u00C3")) %>%
    mutate(value = str_replace_all(value, "\u00C3\u00a4", "\u00e4"))%>%
    mutate(value = str_replace_all(value, "\u00C3\u00b6", "\u00f6"))%>%
    mutate(value = str_replace_all(value, "\u00C3\u00bc", "\u00fc")) %>%
    mutate(value = str_remove_all(value, "\u00C3"))
  
  write_tsv(data_overview, file_overview)
}

clean_price <- function(data_price, file_price) {
  data_price <- data_price %>%
    mutate(date = str_replace_all(date, "\u00C3\u00a4", "\u00e4")) %>%
    mutate(date = str_replace(date, "Jan", "J\u00e4n")) %>%
    mutate(date = as.Date(date, format = "%d.%b.%Y")) %>%
    mutate(price = as.numeric(price))
  
  if (file.exists(file_price)) {
    data_price <- bind_rows(data_price, old_price) %>%
      unique() %>%
      group_by(date) %>%
      filter(row_number() == 1) %>%
      ungroup() %>%
      arrange(desc(date))
  }
  
  write_tsv(data_price, file_price)
}
  
clean_dividends <- function(data_xml, data_dividends, file_dividends) {
  data_dividends <- data_dividends %>%
    mutate(date = str_replace_all(date, "\u00C3\u00a4", "\u00e4")) %>%
    mutate(date = str_replace(date, "Jan", "J\u00e4n")) %>%
    mutate(date = as.Date(date, format = "%d.%b.%Y")) %>%
    mutate(dividend = as.numeric(dividend)) %>%
    filter(!is.na(dividend) & dividend != 0)
  
  if (xml_length(data_xml) == 6 & file.exists(file_dividends)) {
    data_dividends <- bind_rows(data_dividends, old_dividends) %>%
      unique() %>%
      group_by(date) %>%
      filter(row_number() == 1) %>%
      ungroup() %>%
      arrange(desc(date))
  }
  
  write_tsv(data_dividends, file_dividends)
}
```

## Complete function for ishares download

The complete function to download the ETF data from iShares:

```{r, echo = TRUE, results = "hide"}
download_ishares <- function(etf_name, etf_url) {
  file_overview <- file.path(dir_price, str_c(etf_name, "_overview.tsv"))
  file_price <- file.path(dir_price, str_c(etf_name, "_price.tsv"))
  file_dividends <- file.path(dir_price, str_c(etf_name, "_dividends.tsv"))
  
  data_xml <- get_xml(etf_url)
  data_overview <- extract_overview(data_xml)
  data_price <- extract_historic(data_xml, file_price)
  data_dividends <- extract_dividends(data_xml, file_dividends)
  
  clean_overview(data_overview, file_overview)
  clean_price(data_price, file_price)
  clean_dividends(data_xml, data_dividends, file_dividends)
}
```

Map the `download_ishares` function to the list of ETF names and URLs `[data_etf]`:

```{r, echo = TRUE, eval = FALSE}
map2(data_etf$name, data_etf$url, ishares_scrap_fun)
```

The output are three files for each ETF that contain cleaned overview data, historic prices, and dividends:

```{r, echo = FALSE, warning = FALSE, message = FALSE}
read_tsv(file.path(dir_overview, "DivDax_overview.tsv"))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
read_tsv(file.path(dir_price, "DivDax_price.tsv"))
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
read_tsv(file.path(dir_dividends, "DivDax_dividends.tsv"))
```

# Convert to Euro returns and save data

# Summarize the data

